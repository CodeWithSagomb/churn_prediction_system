# params.yml

# --- 1. Configuration des Chemins de Fichiers ---
# Chemins pour les données et les artefacts du modèle
data:
  raw_data_path: "C:/Users/pc/Documents/churn_prediction_system/data/WA_Fn-UseC_-Telco-Customer-Churn.csv"
  preprocessor_path: "data/preprocessor.joblib"
    

# --- 2. Paramètres du Pipeline de Prétraitement ---
preprocessing:
  test_size: 0.2
  random_state: 42 # Graine pour la reproductibilité

# --- 3. Configuration de l'Entraînement des Modèles ---
training:
  experiment_name: "Churn_Prediction_Multi_Model_MVP"
  # Paramètres pour la recherche d'hyperparamètres avec RandomizedSearchCV
  hyperparameter_tuning:
    n_iter: 10       # Nombre d'itérations pour la recherche aléatoire (plus élevé = plus long mais potentiellement meilleur)
    cv: 5            # Nombre de plis pour la validation croisée
    scoring: "f1" # Métrique à optimiser

# --- 4. Définition des Modèles et de leurs Grilles d'Hyperparamètres ---
models:
  RandomForest:
    # Paramètres à rechercher pour RandomForestClassifier
    # Le préfixe 'model__' est nécessaire car le modèle est une étape dans notre pipeline (SMOTE -> model)
    param_grid:
      model__n_estimators: [100, 200, 300]
      model__max_depth: [10, 20, 30, null]
      model__min_samples_split: [2, 5, 10]
      model__min_samples_leaf: [1, 2, 4]

  XGBoost:
    # Paramètres à rechercher pour XGBClassifier
    param_grid:
      model__n_estimators: [100, 200, 300]
      model__learning_rate: [0.01, 0.1, 0.2]
      model__max_depth: [3, 5, 7]
      model__subsample: [0.7, 0.8, 0.9]
      model__colsample_bytree: [0.7, 0.8, 0.9]

  MLPClassifier:
    # Paramètres à rechercher pour MLPClassifier (Réseau de Neurones)
    param_grid:
      model__hidden_layer_sizes: [[50, 50], [100]]  # Teste deux architectures : 2 couches de 50 neurones, ou 1 couche de 100
      model__activation: ['relu', 'tanh']
      model__solver: ['adam']
      model__alpha: [0.01, 0.05]
      model__learning_rate: ['constant', 'adaptive']